@Article{Watkins1992,
author="Watkins, Christopher J. C. H.
and Dayan, Peter",
title="Q-learning",
journal="Machine Learning",
year="1992",
volume="8",
number="3",
pages="279--292",
abstract="Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.",
issn="1573-0565",
doi="10.1007/BF00992698",
url="http://dx.doi.org/10.1007/BF00992698"
}

@misc{Wiki,
title = {Sokoban Wiki},
howpublished = {\url{http://www.sokobano.de/wiki}},
note = {[Online; accessed 24-April-2017]}
}

@Article{Littman94markovgames,
author = {Michael L. Littman},
title = {Markov games as a framework for multi-agent reinforcement learning},
booktitle = {IN PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING},
year = {1994},
pages = {157--163},
publisher = {Morgan Kaufmann}
}

@Article{Guo,
author = {M. Guo and Y. Liu and J. Malee},
title = {A new Q-learning algorithm based on the metropolis criterion},
journal = {IEEE Transactions on Systems, Man, and Cybernetics, part B (cybernetics)},
volume = {34},
number = {5},
year = {2004},
pages = {2140--2143}
}

@Book{Russell,
author = {S. J. Russell and P. Norvig},
title = {Artificial Intelligence: a modern approach},
year = {2010},
publisher = {Prentice Hall}
}

@MISC{Pspace-complete97sokobanis,
    author = {Sokoban Is Pspace-complete and Joseph C. Culberson and Joseph C. Culberson},
    title = {Sokoban is PSPACE-complete},
    year = {1997}
}
